@ARTICLE{6389682,
  author={Hu, Yao and Zhang, Debing and Ye, Jieping and Li, Xuelong and He, Xiaofei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Fast and Accurate Matrix Completion via Truncated Nuclear Norm Regularization}, 
  year={2013},
  volume={35},
  number={9},
  pages={2117-2130},
  doi={10.1109/TPAMI.2012.271}}

@article{Li2019ASO,
  title={A Survey on Matrix Completion: Perspective of Signal Processing},
  author={Xiao Peng Li and Lei Huang and Hing Cheung So and Bo Zhao},
  journal={arXiv: Signal Processing},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:84843204}
}

@INPROCEEDINGS{8265431,
  author={Rezaei, Behnaz and Ostadabbas, Sarah},
  booktitle={2017 IEEE International Conference on Computer Vision Workshops (ICCVW)}, 
  title={Background Subtraction via Fast Robust Matrix Completion}, 
  year={2017},
  volume={},
  number={},
  pages={1871-1879},
  doi={10.1109/ICCVW.2017.221}}



@inproceedings{Bennett2007TheNP,
  title={The Netflix Prize},
  author={James Bennett and Stan Lanning},
  year={2007},
  url={https://api.semanticscholar.org/CorpusID:9528522}
}

@INPROCEEDINGS{945730,
  author={Fazel, M. and Hindi, H. and Boyd, S.P.},
  booktitle={Proceedings of the 2001 American Control Conference. (Cat. No.01CH37148)}, 
  title={A rank minimization heuristic with application to minimum order system approximation}, 
  year={2001},
  volume={6},
  number={},
  pages={4734-4739 vol.6},
  doi={10.1109/ACC.2001.945730}}

@phdthesis{Fazel2002MatrixRank,
  author       = {Maryam Fazel},
  title        = {Matrix Rank Minimization with Applications},
  school       = {Stanford University},
  year         = 2002,
  address      = {Redwood City},
  type         = {PhD Thesis}
}


@misc{pokutta2023frankwolfe,
      title={The Frank-Wolfe algorithm: a short introduction}, 
      author={Sebastian Pokutta},
      year={2023},
      eprint={2311.05313},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}
@article{Ma2009FixedPA,
  title={Fixed point and Bregman iterative methods for matrix rank minimization},
  author={Shiqian Ma and Donald Goldfarb and Lifeng Chen},
  journal={Mathematical Programming},
  year={2009},
  volume={128},
  pages={321-353},
  url={https://api.semanticscholar.org/CorpusID:10916354}
}

@inproceedings{NIPS2004_e0688d13,
 author = {Srebro, Nathan and Rennie, Jason and Jaakkola, Tommi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {L. Saul and Y. Weiss and L. Bottou},
 pages = {},
 publisher = {MIT Press},
 title = {Maximum-Margin Matrix Factorization},
 url = {https://proceedings.neurips.cc/paper_files/paper/2004/file/e0688d13958a19e087e123148555e4b4-Paper.pdf},
 volume = {17},
 year = {2004}
}

@article{2019PolarAlignment,
  url = {http://dx.doi.org/10.1561/2400000028},
  year = {2020},
  volume = {3},
  journal = {Foundations and Trends in Optimization},
  title = {Atomic Decomposition via Polar Alignment: The Geometry of Structured Optimization},
  doi = {10.1561/2400000028},
  issn = {2167-3888},
  number = {4},
  pages = {280-366},
  author = {Zhenan Fan and Halyun Jeong and Yifan Sun and Michael P. Friedlander}
}

@inproceedings{NIPS2009_c45147de,
 author = {Wright, John and Ganesh, Arvind and Rao, Shankar and Peng, Yigang and Ma, Yi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. Williams and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization},
 url = {https://proceedings.neurips.cc/paper_files/paper/2009/file/c45147dee729311ef5b5c3003946c48f-Paper.pdf},
 volume = {22},
 year = {2009}
}

@inproceedings{Toh2009AnAP,
  title={An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems},
  author={Kim-Chuan Toh and Sangwoon Yun},
  year={2009},
  url={https://api.semanticscholar.org/CorpusID:9221252}
}

@article{TaleghaniSalahi2019,
  title={An ADMM-Factorization Algorithm for Low Rank Matrix Completion},
  author={Taleghani, Rahman and Salahi, Maziar},
  journal={Applications and Applied Mathematics: An International Journal (AAM)},
  volume={14},
  number={2},
  pages={Article 34},
  year={2019}
}

@ARTICLE{7536166,
  author={Sun, Ruoyu and Luo, Zhi-Quan},
  journal={IEEE Transactions on Information Theory}, 
  title={Guaranteed Matrix Completion via Non-Convex Factorization}, 
  year={2016},
  volume={62},
  number={11},
  pages={6535-6579},
  doi={10.1109/TIT.2016.2598574}}


@InProceedings{pmlr-v54-yurtsever17a,
  title = 	 {{Sketchy Decisions: Convex Low-Rank Matrix Optimization with Optimal Storage}},
  author = 	 {Yurtsever, Alp and Udell, Madeleine and Tropp, Joel and Cevher, Volkan},
  booktitle = 	 {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1188--1196},
  year = 	 {2017},
  editor = 	 {Singh, Aarti and Zhu, Jerry},
  volume = 	 {54},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {20--22 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v54/yurtsever17a/yurtsever17a.pdf},
  url = 	 {https://proceedings.mlr.press/v54/yurtsever17a.html},
  abstract = 	 {This paper concerns a fundamental class of convex matrix optimization problems. It presents the first algorithm that uses optimal storage and provably computes a low-rank approximation of a solution. In particular, when all solutions have low rank, the algorithm converges to a solution. This algorithm, SketchyCGM, modifies a standard convex optimization scheme, the conditional gradient method, to store only a small randomized sketch of the matrix variable. After the optimization terminates, the algorithm extracts a low-rank approximation of the solution from the sketch. In contrast to nonconvex heuristics, the guarantees for SketchyCGM do not rely on statistical models for the problem data. Numerical work demonstrates the benefits of SketchyCGM over heuristics.}
}




@InProceedings{pmlr-v28-jaggi13,
  title = 	 {Revisiting {Frank-Wolfe}: Projection-Free Sparse Convex Optimization},
  author = 	 {Jaggi, Martin},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {427--435},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {1},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/jaggi13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/jaggi13.html},
  abstract = 	 {We provide stronger and more general primal-dual convergence results for Frank-Wolfe-type algorithms (a.k.a. conditional gradient) for constrained convex optimization, enabled by a simple framework of duality gap certificates. Our analysis also holds if the linear subproblems are only solved approximately (as well as if the gradients are inexact), and is proven to be worst-case optimal in the sparsity of the obtained solutions.    On the application side, this allows us to unify a large variety of existing sparse greedy methods, in particular for optimization over convex hulls of an atomic set, even if those sets can only be approximated, including sparse (or structured sparse) vectors or matrices, low-rank matrices, permutation matrices, or max-norm bounded matrices.    We present a new general framework for convex optimization over matrix factorizations, where every Frank-Wolfe iteration will consist of a low-rank update, and discuss the broad application areas of this approach.}
}

@article{tibshirani1996regression,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={58},
  number={1},
  pages={267--288},
  year={1996},
  publisher={Wiley Online Library}
}


@article{10.1145/2827872,
author = {Harper, F. Maxwell and Konstan, Joseph A.},
title = {The MovieLens Datasets: History and Context},
year = {2015},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/2827872},
doi = {10.1145/2827872},
abstract = {The MovieLens datasets are widely used in education, research, and industry. They are downloaded hundreds of thousands of times each year, reflecting their use in popular press programming books, traditional and online courses, and software. These datasets are a product of member activity in the MovieLens movie recommendation system, an active research platform that has hosted many experiments since its launch in 1997. This article documents the history of MovieLens and the MovieLens datasets. We include a discussion of lessons learned from running a long-standing, live research platform from the perspective of a research organization. We document best practices and limitations of using the MovieLens datasets in new research.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {dec},
articleno = {19},
numpages = {19},
keywords = {ratings, MovieLens, Datasets, recommendations}
}